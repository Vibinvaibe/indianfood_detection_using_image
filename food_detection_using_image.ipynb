{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d846dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "#from tensorflow.keras.engine import Layer, InputSpec\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77117c12",
   "metadata": {},
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "#from tensorflow.keras.engine import Layer, InputSpec\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9045367",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path=\"E:\\datasets\\self_food\\self_food_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6290a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=r\"E:\\datasets\\image_set01\\Indian Food Images\\Indian Food Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41251c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_names=os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae54ce0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adhirasam', 'aloo_gobi', 'aloo_matar', 'aloo_methi',\n",
       "       'aloo_shimla_mirch', 'aloo_tikki', 'anarsa', 'ariselu',\n",
       "       'bandar_laddu', 'basundi', 'bhatura', 'bhindi_masala', 'biryani',\n",
       "       'boondi', 'butter_chicken', 'chak_hao_kheer', 'cham_cham',\n",
       "       'chana_masala', 'chapati', 'chhena_kheeri', 'chicken_razala',\n",
       "       'chicken_tikka', 'chicken_tikka_masala', 'chikki',\n",
       "       'daal_baati_churma', 'daal_puri', 'dal_makhani', 'dal_tadka',\n",
       "       'dharwad_pedha', 'doodhpak', 'double_ka_meetha', 'dum_aloo',\n",
       "       'gajar_ka_halwa', 'gavvalu', 'ghevar', 'gulab_jamun', 'imarti',\n",
       "       'jalebi', 'kachori', 'kadai_paneer', 'kadhi_pakoda', 'kajjikaya',\n",
       "       'kakinada_khaja', 'kalakand', 'karela_bharta', 'kofta',\n",
       "       'kuzhi_paniyaram', 'lassi', 'ledikeni', 'litti_chokha', 'lyangcha',\n",
       "       'maach_jhol', 'makki_di_roti_sarson_da_saag', 'malapua',\n",
       "       'misi_roti', 'misti_doi', 'modak', 'mysore_pak', 'naan',\n",
       "       'navrattan_korma', 'palak_paneer', 'paneer_butter_masala',\n",
       "       'phirni', 'pithe', 'poha', 'poornalu', 'pootharekulu',\n",
       "       'qubani_ka_meetha', 'rabri', 'rasgulla', 'ras_malai', 'sandesh',\n",
       "       'shankarpali', 'sheera', 'sheer_korma', 'shrikhand', 'sohan_halwa',\n",
       "       'sohan_papdi', 'sutar_feni', 'unni_appam'], dtype='<U28')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(food_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f04b50f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(food_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de508c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_Shape = (200,200,3)\n",
    "train_ids = np.arange(0,30)\n",
    "val_ids = np.arange(30,40)\n",
    "test_ids = np.arange(40,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ad8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimgs(names,n = 0,dataset=\"train\"):\n",
    "    X_train=[]\n",
    "    X_val = []\n",
    "    y_train = []\n",
    "    y_val =[]\n",
    "    X_test = []\n",
    "    y_test =[]\n",
    "    \n",
    "    img_shape = (200,200)\n",
    "    cat_dict = {}\n",
    "    dish_dict = {}\n",
    "    curr_y = n\n",
    "    path = train_dir\n",
    "    \n",
    "    category_images_tr=[]\n",
    "    category_images_v=[]\n",
    "    category_images_te=[] \n",
    "        \n",
    "    clsctr = 0\n",
    "    for dish in names:\n",
    "        dish_dict[dish] = clsctr\n",
    "        dish_path = os.path.join(path,dish) +'/'\n",
    "        \n",
    "        #category_images_t=[]\n",
    "        #category_images_v=[]\n",
    "                  \n",
    "        #count = 0 \n",
    "        #print(len(os.listdir(dish_path)))\n",
    "        for count, filename in enumerate(os.listdir(dish_path)):\n",
    "            #print(\"Class :{}, count: {}\".format(clsctr,count)) \n",
    "            if count < 30:\n",
    "                #print(\"In train condition\")\n",
    "                image_path = os.path.join(dish_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                resized_image = cv2.resize(image, img_shape)\n",
    "                final_image = resized_image #cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "                y_train.append(clsctr)\n",
    "                try:\n",
    "                    category_images_tr.append(final_image)\n",
    "            \n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(\"error - category_images_train:\", final_image)\n",
    "    \n",
    "                \n",
    "            elif count >= 30 and count < 40:\n",
    "                #print(\"In val condition\")\n",
    "                image_path = os.path.join(dish_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                resized_image = cv2.resize(image, img_shape)\n",
    "                final_image = resized_image#cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "                y_val.append(clsctr)\n",
    "                try:\n",
    "                    category_images_v.append(final_image)\n",
    "            \n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(\"error - category_images_test:\", final_image)\n",
    "             \n",
    "            \n",
    "            else :\n",
    "                #print(\"In test condition\")\n",
    "                image_path = os.path.join(dish_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                resized_image = cv2.resize(image, img_shape)\n",
    "                final_image = resized_image#cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "                y_test.append(clsctr)\n",
    "                try:\n",
    "                    category_images_te.append(final_image)\n",
    "            \n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(\"error - category_images_test:\", final_image)\n",
    "             \n",
    "            curr_y += 1    \n",
    "             \n",
    "             #count = count + 1\n",
    "            \n",
    "        #X_train.append(category_images_t)\n",
    "        #X_val.append(category_images_v)\n",
    "        clsctr += 1\n",
    "    \n",
    "    #y_train = np.vstack(y_train)\n",
    "    #y_val = np.vstack(y_val)\n",
    "    #X_train = np.stack(X_train)\n",
    "    #X_val = np.stack(X_val)\n",
    "    X_train = category_images_tr\n",
    "    X_val = category_images_v\n",
    "    X_test = category_images_te\n",
    "    \n",
    "    #print(y_train)\n",
    "    \n",
    "    return X_train,y_train, X_val,y_val, X_test,y_test, dish_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50e0e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 800, 2400, 800, 800, 800)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train,X_val,y_val,X_test,y_test, dish_dict = loadimgs(food_names)\n",
    "len(X_train), len(X_val), len(y_train), len(y_val), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e6f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(images, labels):\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    random.seed(2021)\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "   \n",
    "    # calculate the total number of classes present in the dataset\n",
    "    # and then build a list of indexes for each class label that\n",
    "    # provides the indexes for all examples with a given label\n",
    "    numClasses = len(np.unique(y_val))\n",
    "    classes=np.unique(y_val)\n",
    "    idx = [np.where(y_val == classes[i]) for i in range(0, numClasses)]\n",
    "    \n",
    "    # loop over all images\n",
    "    for idxA in range(len(images)):\n",
    "        # grab the current image and label belonging to the current iteration\n",
    "        currentImage = images[idxA]\n",
    "        label = labels[idxA]\n",
    "        \n",
    "        # randomly pick an image that belongs to the *same* class\n",
    "        # label\n",
    "        #posId = random.choice(list(np.where(labels == label)))\n",
    "        posIdx =random.choice([index for index, element in enumerate(labels) if element == label])\n",
    "        posImage = images[posIdx]\n",
    "        \n",
    "        # prepare a positive pair and update the images and labels\n",
    "        pairImages.append([currentImage, posImage])\n",
    "        pairLabels.append([1])\n",
    "        \n",
    "        # grab the indices for each of the class labels *not* equal to\n",
    "        # the current label and randomly pick an image corresponding\n",
    "        # to a label *not* equal to the current label\n",
    "        #negId = random.choice(list(np.where(labels != label)))         \n",
    "        negIdx =random.choice([index for index, element in enumerate(labels) if element != label])\n",
    "        negImage = images[negIdx]\n",
    "        \n",
    "        # prepare a negative pair of images and update our lists\n",
    "        pairImages.append([currentImage, negImage])\n",
    "        pairLabels.append([0])\n",
    "   \n",
    "    return (np.array(pairImages), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "950d41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pairTrain, labelTrain) = create_pairs(X_train, y_train)\n",
    "(pairval, labelval) = create_pairs(X_val, y_val)\n",
    "(pairTest, labelTest) = create_pairs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca2b6483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, 6, 6, 512)         20024384  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                32832     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,057,216\n",
      "Trainable params: 2,392,640\n",
      "Non-trainable params: 17,664,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def tf_siamese_nn(shape, embedding=64, fineTune=False):\n",
    "    inputs = tf.keras.layers.Input(shape)\n",
    "    preprocess_fn = preprocess_input\n",
    "    base_model = tf.keras.applications.vgg19.VGG19(input_shape=shape, include_top=False,                                               weights='imagenet')\n",
    "    \n",
    "    if fineTune==False:\n",
    "        base_model.trainable=False\n",
    "    else:\n",
    "        base_model.trainable = True\n",
    "        # Fine-tune from this layer onwards\n",
    "        fine_tune_at = len(base_model.layers)-int(len(base_model.layers)*.10)\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "          layer.trainable =  False\n",
    "    x=base_model(inputs)\n",
    "    x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs=tf.keras.layers.Dense(embedding)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model1=tf_siamese_nn(IMG_Shape, 64, True)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6b0a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    # unpack the vectors into separate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d9573b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = tf.keras.layers.Input(shape=IMG_Shape)\n",
    "img2 =  tf.keras.layers.Input( shape=IMG_Shape)\n",
    "featureExtractor = tf_siamese_nn(IMG_Shape)\n",
    "featsA = featureExtractor(img1)\n",
    "featsB = featureExtractor(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "138b4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92ef9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = tf.keras.Model(inputs=[img1, img2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6c27ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b29e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = r'C:\\Users\\vaibh\\notebooks\\khana\\checkpoint'\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    save_freq='epoch',\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e6b6679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4800/4800 [==============================] - 161s 29ms/step - loss: 7.5611 - accuracy: 0.5658 - val_loss: 0.6049 - val_accuracy: 0.6450\n",
      "Epoch 2/20\n",
      "1514/4800 [========>.....................] - ETA: 1:22 - loss: 0.5642 - accuracy: 0.7153"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpairTrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairTrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabelTrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpairval\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairval\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabelval\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mE:\\anaconda3\\envs\\hell\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:], validation_data=([pairval[:, 0], pairval[:, 1]], labelval[:]), batch_size=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict( [pairTest[:,0],pairTest[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ = [int(i > .5) for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTest = labelTest.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    correct_predictions = 0\n",
    "    # iterate over each label and check\n",
    "    for true, predicted in zip(y_true, y_pred):\n",
    "        if true == predicted:\n",
    "            correct_predictions += 1\n",
    "    # compute the accuracy\n",
    "    accuracy = correct_predictions/len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy(labelTest,preds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimgs_(names):\n",
    "    '''\n",
    "    path => Path of train directory or test directory\n",
    "    '''\n",
    "    images = []\n",
    "    labels = [] \n",
    "    \n",
    "    img_shape = (200,200)\n",
    "    dish_dict = {}\n",
    "    \n",
    "    path = train_dir\n",
    "    \n",
    "    category_images = []\n",
    "        \n",
    "    clsctr = 0\n",
    "    for dish in names:\n",
    "        dish_dict[dish] = clsctr\n",
    "        dish_path = os.path.join(path,dish) +'/'\n",
    "        \n",
    "        for count, filename in enumerate(os.listdir(dish_path)):\n",
    "            #print(\"Class :{}, count: {}\".format(clsctr,count)) \n",
    "            if count == 1:\n",
    "                #print(\"In train condition\")\n",
    "                image_path = os.path.join(dish_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                resized_image = cv2.resize(image, img_shape)\n",
    "                final_image = resized_image #cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "                labels.append(clsctr)\n",
    "                try:\n",
    "                    category_images.append(final_image)\n",
    "            \n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(\"error - category_images_train:\", final_image)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        clsctr += 1\n",
    "        \n",
    "    images = category_images\n",
    "    \n",
    "    return images, labels, dish_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_, labels_ , dish_dict_ = loadimgs_(food_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d609a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs_for_pred(image_path, images_):\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    random.seed(2021)\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "   \n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, (200,200))\n",
    "                \n",
    "    # loop over all images\n",
    "    for idxA in range(len(images_)):\n",
    "    \n",
    "        currentImage = images_[idxA]\n",
    "\n",
    "        pairImages.append([currentImage, resized_image]) \n",
    "   \n",
    "    return (np.array(pairImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"D:\\New folder\\download (1).jpg\"\n",
    "pairPred = create_pairs_for_pred(image_path, images_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005ffa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_prediction = model.predict( [pairPred[:,0],pairPred[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e53c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_food_name=list(dish_dict.keys())[list(dish_dict.values()).index(np.argmax(image_prediction))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829624a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The image is of {}\".format(list(dish_dict.keys())[list(dish_dict.values()).index(np.argmax(image_prediction))])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dbeff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
