{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d846dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "#from tensorflow.keras.engine import Layer, InputSpec\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77117c12",
   "metadata": {},
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "#from tensorflow.keras.engine import Layer, InputSpec\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9045367",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path=\"E:\\datasets\\self_food\\self_food_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=r\"E:\\datasets\\image_set01\\Indian Food Images\\Indian Food Images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41251c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_names=os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54ce0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(food_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(food_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de508c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_Shape = (200,200,3)\n",
    "train_ids = np.arange(0,30)\n",
    "val_ids = np.arange(30,40)\n",
    "test_ids = np.arange(40,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimgs(names,n = 0,dataset=\"train\"):\n",
    "    X_train=[]\n",
    "    X_val = []\n",
    "    y_train = []\n",
    "    y_val =[]\n",
    "    X_test = []\n",
    "    y_test =[]\n",
    "    \n",
    "    img_shape = (200,200)\n",
    "    cat_dict = {}\n",
    "    dish_dict = {}\n",
    "    curr_y = n\n",
    "    path = train_dir\n",
    "    \n",
    "    category_images_tr=[]\n",
    "    category_images_v=[]\n",
    "    category_images_te=[] \n",
    "        \n",
    "    clsctr = 0\n",
    "    for dish in names:\n",
    "        dish_dict[dish] = clsctr\n",
    "        dish_path = os.path.join(path,dish) +'/'\n",
    "        \n",
    "        #category_images_t=[]\n",
    "        #category_images_v=[]\n",
    "                  \n",
    "        #count = 0 \n",
    "        #print(len(os.listdir(dish_path)))\n",
    "        for count, filename in enumerate(os.listdir(dish_path)):\n",
    "            #print(\"Class :{}, count: {}\".format(clsctr,count)) \n",
    "            if count < 30:\n",
    "                #print(\"In train condition\")\n",
    "                image_path = os.path.join(dish_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                resized_image = cv2.resize(image, img_shape)\n",
    "                final_image = resized_image #cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "                y_train.append(clsctr)\n",
    "                try:\n",
    "                    category_images_tr.append(final_image)\n",
    "            \n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(\"error - category_images_train:\", final_image)\n",
    "    \n",
    "                \n",
    "            elif count >= 30 and count < 40:\n",
    "                #print(\"In val condition\")\n",
    "                image_path = os.path.join(dish_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                resized_image = cv2.resize(image, img_shape)\n",
    "                final_image = resized_image#cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "                y_val.append(clsctr)\n",
    "                try:\n",
    "                    category_images_v.append(final_image)\n",
    "            \n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(\"error - category_images_test:\", final_image)\n",
    "             \n",
    "            \n",
    "            else :\n",
    "                #print(\"In test condition\")\n",
    "                image_path = os.path.join(dish_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                resized_image = cv2.resize(image, img_shape)\n",
    "                final_image = resized_image#cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "                y_test.append(clsctr)\n",
    "                try:\n",
    "                    category_images_te.append(final_image)\n",
    "            \n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(\"error - category_images_test:\", final_image)\n",
    "             \n",
    "            curr_y += 1    \n",
    "             \n",
    "             #count = count + 1\n",
    "            \n",
    "        #X_train.append(category_images_t)\n",
    "        #X_val.append(category_images_v)\n",
    "        clsctr += 1\n",
    "    \n",
    "    #y_train = np.vstack(y_train)\n",
    "    #y_val = np.vstack(y_val)\n",
    "    #X_train = np.stack(X_train)\n",
    "    #X_val = np.stack(X_val)\n",
    "    X_train = category_images_tr\n",
    "    X_val = category_images_v\n",
    "    X_test = category_images_te\n",
    "    \n",
    "    #print(y_train)\n",
    "    \n",
    "    return X_train,y_train, X_val,y_val, X_test,y_test, dish_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e0e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train,X_val,y_val,X_test,y_test, dish_dict = loadimgs(food_names)\n",
    "len(X_train), len(X_val), len(y_train), len(y_val), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(images, labels):\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    random.seed(2021)\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "   \n",
    "    # calculate the total number of classes present in the dataset\n",
    "    # and then build a list of indexes for each class label that\n",
    "    # provides the indexes for all examples with a given label\n",
    "    numClasses = len(np.unique(y_val))\n",
    "    classes=np.unique(y_val)\n",
    "    idx = [np.where(y_val == classes[i]) for i in range(0, numClasses)]\n",
    "    \n",
    "    # loop over all images\n",
    "    for idxA in range(len(images)):\n",
    "        # grab the current image and label belonging to the current iteration\n",
    "        currentImage = images[idxA]\n",
    "        label = labels[idxA]\n",
    "        \n",
    "        # randomly pick an image that belongs to the *same* class\n",
    "        # label\n",
    "        #posId = random.choice(list(np.where(labels == label)))\n",
    "        posIdx =random.choice([index for index, element in enumerate(labels) if element == label])\n",
    "        posImage = images[posIdx]\n",
    "        \n",
    "        # prepare a positive pair and update the images and labels\n",
    "        pairImages.append([currentImage, posImage])\n",
    "        pairLabels.append([1])\n",
    "        \n",
    "        # grab the indices for each of the class labels *not* equal to\n",
    "        # the current label and randomly pick an image corresponding\n",
    "        # to a label *not* equal to the current label\n",
    "        #negId = random.choice(list(np.where(labels != label)))         \n",
    "        negIdx =random.choice([index for index, element in enumerate(labels) if element != label])\n",
    "        negImage = images[negIdx]\n",
    "        \n",
    "        # prepare a negative pair of images and update our lists\n",
    "        pairImages.append([currentImage, negImage])\n",
    "        pairLabels.append([0])\n",
    "   \n",
    "    return (np.array(pairImages), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pairTrain, labelTrain) = create_pairs(X_train, y_train)\n",
    "(pairval, labelval) = create_pairs(X_val, y_val)\n",
    "(pairTest, labelTest) = create_pairs(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_siamese_nn(shape, embedding=64, fineTune=False):\n",
    "    inputs = tf.keras.layers.Input(shape)\n",
    "    preprocess_fn = preprocess_input\n",
    "    base_model = tf.keras.applications.vgg19.VGG19(input_shape=shape, include_top=False,                                               weights='imagenet')\n",
    "    \n",
    "    if fineTune==False:\n",
    "        base_model.trainable=False\n",
    "    else:\n",
    "        base_model.trainable = True\n",
    "        # Fine-tune from this layer onwards\n",
    "        fine_tune_at = len(base_model.layers)-int(len(base_model.layers)*.10)\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "          layer.trainable =  False\n",
    "    x=base_model(inputs)\n",
    "    x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs=tf.keras.layers.Dense(embedding)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model1=tf_siamese_nn(IMG_Shape, 64, True)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    # unpack the vectors into separate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9573b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = tf.keras.layers.Input(shape=IMG_Shape)\n",
    "img2 =  tf.keras.layers.Input( shape=IMG_Shape)\n",
    "featureExtractor = tf_siamese_nn(IMG_Shape)\n",
    "featsA = featureExtractor(img1)\n",
    "featsB = featureExtractor(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = tf.keras.layers.Lambda(euclidean_distance)([featsA, featsB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = tf.keras.Model(inputs=[img1, img2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c27ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = r'C:\\Users\\vaibh\\notebooks\\khana\\checkpoint'\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    save_freq='epoch',\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b6679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit([pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:], validation_data=([pairval[:, 0], pairval[:, 1]], labelval[:]), batch_size=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict( [pairTest[:,0],pairTest[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ = [int(i > .5) for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTest = labelTest.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    correct_predictions = 0\n",
    "    # iterate over each label and check\n",
    "    for true, predicted in zip(y_true, y_pred):\n",
    "        if true == predicted:\n",
    "            correct_predictions += 1\n",
    "    # compute the accuracy\n",
    "    accuracy = correct_predictions/len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy(labelTest,preds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimgs_(names):\n",
    "    '''\n",
    "    path => Path of train directory or test directory\n",
    "    '''\n",
    "    images = []\n",
    "    labels = [] \n",
    "    \n",
    "    img_shape = (200,200)\n",
    "    dish_dict = {}\n",
    "    \n",
    "    path = train_dir\n",
    "    \n",
    "    category_images = []\n",
    "        \n",
    "    clsctr = 0\n",
    "    for dish in names:\n",
    "        dish_dict[dish] = clsctr\n",
    "        dish_path = os.path.join(path,dish) +'/'\n",
    "        \n",
    "        for count, filename in enumerate(os.listdir(dish_path)):\n",
    "            #print(\"Class :{}, count: {}\".format(clsctr,count)) \n",
    "            if count == 1:\n",
    "                #print(\"In train condition\")\n",
    "                image_path = os.path.join(dish_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                resized_image = cv2.resize(image, img_shape)\n",
    "                final_image = resized_image #cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "                labels.append(clsctr)\n",
    "                try:\n",
    "                    category_images.append(final_image)\n",
    "            \n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "                    print(\"error - category_images_train:\", final_image)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        clsctr += 1\n",
    "        \n",
    "    images = category_images\n",
    "    \n",
    "    return images, labels, dish_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_, labels_ , dish_dict_ = loadimgs_(food_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d609a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs_for_pred(image_path, images_):\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    random.seed(2021)\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "   \n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, (200,200))\n",
    "                \n",
    "    # loop over all images\n",
    "    for idxA in range(len(images_)):\n",
    "    \n",
    "        currentImage = images_[idxA]\n",
    "\n",
    "        pairImages.append([currentImage, resized_image]) \n",
    "   \n",
    "    return (np.array(pairImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"D:\\New folder\\download (1).jpg\"\n",
    "pairPred = create_pairs_for_pred(image_path, images_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005ffa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_prediction = model.predict( [pairPred[:,0],pairPred[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_food_name=list(dish_dict.keys())[list(dish_dict.values()).index(np.argmax(image_prediction))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829624a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The image is of {}\".format(list(dish_dict.keys())[list(dish_dict.values()).index(np.argmax(image_prediction))])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576a49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
